# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Generate synthetic fraud dataset
np.random.seed(42)

# Normal transactions
n_normal = 10000
normal_transactions = pd.DataFrame({
    'amount': np.random.normal(200, 100, n_normal),
    'time': np.random.normal(12, 16, n_normal),
    'distance_from_home': np.random.normal(10, 5, n_normal),
    'fraud': 0
})

# Fraudulent transactions
n_fraud = 100
fraud_transactions = pd.DataFrame({
    'amount': np.random.normal(500, 200, n_fraud),
    'time': np.random.normal(2, 2, n_fraud),
    'distance_from_home': np.random.normal(50, 20, n_fraud),
    'fraud': 1 # Changed 'Fraud' to 'fraud' to match the column name in normal_transactions
})

# Combine datasets
df = pd.concat([normal_transactions, fraud_transactions])
df = df.sample(frac=1).reset_index(drop=True)

#prepare features and target
x = df.drop('fraud', axis=1)
y = df['fraud']

#split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

#scale features
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train) # Assign the scaled data to x_train_scaled
x_test_scaled = scaler.transform(x_test) # Assign the scaled data to x_test_scaled

#train model without handling imbalance
print("Training model without handling imbalance...")
model_imbalanced = LogisticRegression(class_weight=None)
model_imbalanced.fit(x_train_scaled, y_train) #Use x_train_scaled here

#apply SMOTE to handle imbalance
print("Applying SMOTE to handle imbalance...")
smote = SMOTE(random_state=42)
x_train_balanced, y_train_balanced = smote.fit_resample(x_train_scaled, y_train)

#train madel with balanced data
model_balanced = LogisticRegression()
model_balanced.fit(x_train_balanced, y_train_balanced)

#function to evaluate and display results
def evaluate_and_display(model, x_test, y_test, title):
    y_pred = model.predict(x_test)

    print(f"\n{title}") # Changed (title) to {title} for f-string formatting
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    #plot confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') # Removed redundant figure creation
    plt.title(f'Confusion Matrix - {title}') # Changed (title) to {title} for f-string formatting
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    plt.show()

#Evaluate both models
evaluate_and_display(model_imbalanced, x_test_scaled, y_test, "Model without Imbalance") # Use x_test_scaled here
evaluate_and_display(model_balanced, x_test_scaled, y_test, "Model with SMOTE Imbalance") # Use x_test_scaled here

feature_importance =pd.DataFrame({'feature':x.columns,'importance':model_balanced.coef_[0]})
feature_importance = feature_importance.sort_values(by='importance', ascending=False)
plt.figure(figsize=(10,6))
sns.barplot(x='importance', y='feature', data=feature_importance)
plt.title('Feature Importance Analysis in fraued detection')
plt.show()